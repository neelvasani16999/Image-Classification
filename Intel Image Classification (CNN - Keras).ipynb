{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intel Image Classification (CNN - Keras)\nHello, I hope you are having a great day.\nMy name is Vincent. I am an engineering student at Sorbonne University, located in Paris.\n\nIn this notebook, I will try the process of implementing CNN with Keras in order to classify images.\n1. Firstly, we'll import usefull packages.\n1. Then, we'll load the data, before visualize and preprocess it.\n1. We'll try a simple CNN model and then we will evaluate its performances."},{"metadata":{},"cell_type":"markdown","source":"# Import Packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport os\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle           \nimport matplotlib.pyplot as plt             \nimport cv2                                 \nimport tensorflow as tf                     ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here's our 6 categories that we have to classify.\nclass_names = ['mountain', 'street', 'glacier', 'buildings', 'sea', 'forest']\n\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n#class_names_label = {'mountain': 0,\n#                    'street' : 1,\n#                    'glacier' : 2,\n#                    'buildings' : 3,\n#                    'sea' : 4,\n#                    'forest' : 5\n#                    }\n\nnb_classes = len(class_names)\n#nb_classes = 6\n\nIMAGE_SIZE = (150, 150)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading the Data\nWe have to write a load_data function that load the images and the labels from the folder."},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data():\n    \"\"\"\n        Load the data:\n            - 14,034 images to train the network.\n            - 3,000 images to evaluate how accurately the network learned to classify images.\n    \"\"\"\n    \n    datasets = ['../input/seg_train/seg_train', '../input/seg_test/seg_test']\n    output = []\n    \n    # Iterate through training and test sets\n    for dataset in datasets:\n        \n        images = []\n        labels = []\n        \n        print(\"Loading {}\".format(dataset))\n        \n        # Iterate through each folder corresponding to a category\n        for folder in os.listdir(dataset):\n            curr_label = class_names_label[folder]\n            \n            # Iterate through each image in our folder\n            for file in os.listdir(os.path.join(dataset, folder)):\n                \n                # Get the path name of the image\n                img_path = os.path.join(os.path.join(dataset, folder), file)\n                \n                # Open and resize the img\n                curr_img = cv2.imread(img_path)\n                curr_img = cv2.resize(curr_img, IMAGE_SIZE) \n                \n                # Append the image and its corresponding label to the output\n                images.append(curr_img)\n                labels.append(curr_label)\n                \n        images = np.array(images, dtype = 'float32')\n        labels = np.array(labels, dtype = 'int32')   \n        \n        output.append((images, labels))\n\n    return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(train_images, train_labels), (test_images, test_labels) = load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images, train_labels = shuffle(train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's explore the dataset\nWe can ask ourselves:\n* How many training and testing examples do we have ?\n* What is the size of the images ?\n* What is the proportion of each observed category ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"print (\"Number of training examples: \" + str(train_labels.shape[0]))\nprint (\"Number of testing examples: \" + str(test_labels.shape[0]))\nprint (\"Each image is of size: \" + str(train_images.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot a pie chart\nsizes = np.bincount(train_labels)\nexplode = (0, 0, 0, 0, 0, 0)  \nplt.pie(sizes, explode=explode, labels=class_names,\nautopct='%1.1f%%', shadow=True, startangle=150)\nplt.axis('equal')\nplt.title('Proportion of each observed category')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Good practice: scale the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = train_images / 255.0 \ntest_images = test_images / 255.0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the data\nWe can display a random image from the training set."},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_random_image(class_names, images, labels):\n    \"\"\"\n        Display a random image from the images array and its correspond label from the labels array.\n    \"\"\"\n    \n    index = np.random.randint(images.shape[0])\n    plt.figure()\n    plt.imshow(images[index])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.title('Image #{} : '.format(index) + class_names[labels[index]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_random_image(class_names, train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also display the first 25 images from the training set directly with a loop"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_examples(class_names, images, labels):\n    \"\"\"\n        Display 25 images from the images array with its corresponding labels\n    \"\"\"\n    \n    fig = plt.figure(figsize=(10,10))\n    fig.suptitle(\"Some examples of images of the dataset\", fontsize=16)\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.grid(False)\n        plt.imshow(images[i], cmap=plt.cm.binary)\n        plt.xlabel(class_names[labels[i]])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_examples(class_names, train_images, train_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple Model Creation\n\nSteps are:\n1. Build the model,\n1. Compile the model,\n1. Train / fit the data to the model,\n1. Evaluate the model on the testing set,\n1. Carry out an error analysis of our model.\n\nWe can build an easy model composed of different layers such as:\n* Conv2D: (32 filters of size 3 by 3) The features will be \"extracted\" from the image.\n* MaxPooling2D: The images get half sized.\n* Flatten: Transforms the format of the images from a 2d-array to a 1d-array of 150 150 3 pixel values.\n* Relu  : given a value x, returns max(x, 0).\n* Softmax: 6 neurons, probability that the image belongs to one of the classes."},{"metadata":{"trusted":true},"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (150, 150, 3)), # the nn will learn the good filter to use\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(128, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Then, we can compile it with some parameters such as:\n* **Optimizer**: adam = RMSProp + Momentum.\nWhat is Momentum and RMSProp ?\n* Momentum = takes into account past gradient to have a better update.\n* RMSProp = exponentially weighted average of the squares of past gradients.\n* **Loss function**: we use sparse categorical crossentropy for classification, each images belongs to one class only"},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We fit the model to the data from the training set. The neural network will learn by itself the pattern in order to distinguish each category."},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train_images, train_labels, batch_size=128, epochs=20, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_accuracy_loss(history):\n    \"\"\"\n        Plot the accuracy and the loss during the training of the nn.\n    \"\"\"\n    fig = plt.figure(figsize=(10,5))\n\n    # Plot accuracy\n    plt.subplot(221)\n    plt.plot(history.history['acc'],'bo--', label = \"acc\")\n    plt.plot(history.history['val_acc'], 'ro--', label = \"val_acc\")\n    plt.title(\"train_acc vs val_acc\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epochs\")\n    plt.legend()\n\n    # Plot loss function\n    plt.subplot(222)\n    plt.plot(history.history['loss'],'bo--', label = \"loss\")\n    plt.plot(history.history['val_loss'], 'ro--', label = \"val_loss\")\n    plt.title(\"train_loss vs val_loss\")\n    plt.ylabel(\"loss\")\n    plt.xlabel(\"epochs\")\n\n    plt.legend()\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracy_loss(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** How well the model is doing ? **"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss = model.evaluate(test_images, test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that we achieve 0.76 accuracy on the testing test.\n\nLet's see how the classifier is doing on random images."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(test_images)     # Vector of probabilities\npred_labels = np.argmax(predictions, axis = 1) # We take the highest probability\n\ndisplay_random_image(class_names, test_images, pred_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Error analysis.\n\nWe can try to understand on which kind of images the classifier has trouble."},{"metadata":{"trusted":true},"cell_type":"code","source":"def print_mislabeled_images(class_names, test_images, test_labels, pred_labels):\n    \"\"\"\n        Print 25 examples of mislabeled images by the classifier, e.g when test_labels != pred_labels\n    \"\"\"\n    BOO = (test_labels == pred_labels)\n    mislabeled_indices = np.where(BOO == 0)\n    mislabeled_images = test_images[mislabeled_indices]\n    mislabeled_labels = pred_labels[mislabeled_indices]\n\n    title = \"Some examples of mislabeled images by the classifier:\"\n    display_examples(class_names,  mislabeled_images, mislabeled_labels)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print_mislabeled_images(class_names, test_images, test_labels, pred_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CM = confusion_matrix(test_labels, pred_labels)\nax = plt.axes()\nsn.heatmap(CM, annot=True, \n           annot_kws={\"size\": 10}, \n           xticklabels=class_names, \n           yticklabels=class_names, ax = ax)\nax.set_title('Confusion matrix')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusion: The classifier has trouble with 2 kinds of images.\nIt has trouble with street and buildings. Well, it can be understandable as as there are buildings in the street. \nIt has also trouble with sea, glacier and moutain as well. It is hard for me to fully distinguish them.\nHowever, it can detects forest very accurately!!"},{"metadata":{},"cell_type":"markdown","source":"# Update 2020\n\n* Transfer Learning with VGG\n\nInspired from: https://keras.io/applications/\n\n* Ensemble models of Neural Networks with the features extracted from VGG\n\nInspired from: https://machinelearningmastery.com/model-averaging-ensemble-for-deep-learning-neural-networks/"},{"metadata":{},"cell_type":"markdown","source":"# Transfer Learning with VGG"},{"metadata":{},"cell_type":"markdown","source":"We can extract features from VGG16."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16\nfrom keras.preprocessing import image\nfrom keras.applications.vgg16 import preprocess_input\n\nmodel = VGG16(weights='imagenet', include_top=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the features directly from VGG16"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualize the features through PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"n_train, x, y, z = train_features.shape\nn_test, x, y, z = test_features.shape\nnumFeatures = x * y * z","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import decomposition\n\npca = decomposition.PCA(n_components = 2)\n\nX = train_features.reshape((n_train, x*y*z))\npca.fit(X)\n\nC = pca.transform(X) # Repr√©sentation des individus dans les nouveaux axe\nC1 = C[:,0]\nC2 = C[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Figures\n\nplt.subplots(figsize=(10,10))\n\nfor i, class_name in enumerate(class_names):\n    plt.scatter(C1[train_labels == i][:1000], C2[train_labels == i][:1000], label = class_name)\nplt.legend()\nplt.title(\"PCA Projection\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can identifying clusters thanks to this PCA. The clusters correspond more or less to the labels.\n\nWe see that glacier and mountain points are very close to each other, as VGG sees them as very similar.\n\nWe see that there is no distinction between building and street.\n "},{"metadata":{},"cell_type":"markdown","source":"## Training on top of VGG\n\nLet's train a simple one-layer Neural Network on the features extracted from VGG."},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape = (x, y, z)),\n    tf.keras.layers.Dense(50, activation=tf.nn.relu),\n    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n])\n\nmodel2.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n\nhistory2 = model2.fit(train_features, train_labels, batch_size=128, epochs=15, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracy_loss(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should get approximately 0.844 accuracy (+0.1 accuracy) over the simple ConvNet."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss = model2.evaluate(test_features, test_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble Neural Networks"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.random.seed(seed=1997)\n# Number of estimators\nn_estimators = 10\n# Proporition of samples to use to train each training\nmax_samples = 0.8\n\nmax_samples *= n_train\nmax_samples = int(max_samples)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We define n_estimators Neural Networks. \n\nEach Neural Network will be trained on random subsets of the training dataset. Each subset contains max_samples samples."},{"metadata":{"trusted":true},"cell_type":"code","source":"models = list()\nrandom = np.random.randint(50, 100, size = n_estimators)\n\nfor i in range(n_estimators):\n    \n    # Model\n    model = tf.keras.Sequential([ tf.keras.layers.Flatten(input_shape = (x, y, z)),\n                                # One layer with random size\n                                    tf.keras.layers.Dense(random[i], activation=tf.nn.relu),\n                                    tf.keras.layers.Dense(6, activation=tf.nn.softmax)\n                                ])\n    \n    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    # Store model\n    models.append(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"histories = []\n\nfor i in range(n_estimators):\n    # Train each model on a bag of the training data\n    train_idx = np.random.choice(len(train_features), size = max_samples)\n    histories.append(models[i].fit(train_features[train_idx], train_labels[train_idx], batch_size=128, epochs=10, validation_split = 0.1))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We aggregate each model individual predictions to form a final prediction."},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor i in range(n_estimators):\n    predictions.append(models[i].predict(test_features))\n    \npredictions = np.array(predictions)\npredictions = predictions.sum(axis = 0)\npred_labels = predictions.argmax(axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We should improve our result as we have a lower variance."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nprint(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fine Tuning VGG"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\n\nmodel = VGG16(weights='imagenet', include_top=False)\nmodel = Model(inputs=model.inputs, outputs=model.layers[-5].output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_features = model.predict(train_images)\ntest_features = model.predict(test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Conv2D, Activation , MaxPooling2D, Flatten\n\nmodel2 = VGG16(weights='imagenet', include_top=False)\n\ninput_shape = model2.layers[-4].get_input_shape_at(0) # get the input shape of desired layer\nlayer_input = Input(shape = (9, 9, 512)) # a new input tensor to be able to feed the desired layer\n# https://stackoverflow.com/questions/52800025/keras-give-input-to-intermediate-layer-and-get-final-output\n\nx = layer_input\nfor layer in model2.layers[-4::1]:\n    x = layer(x)\n    \nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Conv2D(64, (3, 3), activation='relu')(x)\nx = Flatten()(x)\nx = Dense(100,activation='relu')(x)\nx = Dense(6,activation='softmax')(x)\n\n# create the model\nnew_model = Model(layer_input, x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = new_model.fit(train_features, train_labels, batch_size=128, epochs=10, validation_split = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_accuracy_loss(history)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\n\npredictions = new_model.predict(test_features)    \npred_labels = np.argmax(predictions, axis = 1)\nprint(\"Accuracy : {}\".format(accuracy_score(test_labels, pred_labels)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}